{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "63b508aec3eb8cad8bd7033d75d8f13670bc1672"
   },
   "source": [
    "# Using Machine Learning to Predict Titanic Survivors\n",
    "\n",
    "This is my first submission for a kaggle competition. I will try to keep things simple and will explain things on the go. In  this notebook I will build a machine learning model using sklearn to predict the outcomes of each passenger aboard titanic. I will build this model step by step. This kernel will help people who are getting started with data visualization, analysis and machine learning.\n",
    "\n",
    "\n",
    "#### If you like my work. Please, leave an upvote, the upvote will me to help to contribute more  and more to the community.\n",
    "\n",
    "#### Please leave your valuable  suggestions in the comments section.\n",
    "\n",
    "#### Follow me for even better kernels than this one.\n",
    "\n",
    "\n",
    "\n",
    "## What type of problem is this one?\n",
    "\n",
    "Since we have to classify passengers as either survived, or not survived. Hence, This is a supervised classification machine learning problem.\n",
    "\n",
    "\n",
    "## Content \n",
    "\n",
    "The file 'train.csv' contains 12 columns and - rows. Each row containes details of individual passenger onboard. The columns  are: \n",
    "\n",
    "1. PassengerId - type should be integers\n",
    "2. Survived - Survived or Not\n",
    "3. PclassClass - of Travel\n",
    "4. Name - Name of Passenger\n",
    "5. Sex - Gender\n",
    "6. Age - Age of passenger\n",
    "7. SibSp - Number of Sibling/Spouse abord\n",
    "8. Parch - Number of Parent/Child abord\n",
    "9. Ticket\n",
    "10. Fare\n",
    "11. Cabin\n",
    "12. EmbarkedThe port in which a passenger has embarked. C - Cherbourg, S - Southampton, Q = Queenstown\n",
    "\n",
    "\n",
    "## Version\n",
    "\n",
    "Version 1.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Index of Content\n",
    "\n",
    "1. Importing packages\n",
    "2. Importing dataset\n",
    "3. Analysing dataset\n",
    "4. Assumptions based on data analysis done so far\n",
    "5. Actions based on assumptions\n",
    "6. Visualizing by plotting data\n",
    "7. Feature Engineering\n",
    "8. Creating New Features\n",
    "9. Build Model and Make Predictions\n",
    "10. Compare Model Performances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8fe51b233f37c4b607eb26815e9be77e3cebcfe1"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## 1. Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "3ed6ea7a551db5456b3f2efd10634305f921d136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender_submission.csv', 'result.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "# data analysis and wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "#Let's import them as and when needed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2ef8501d5acab2a62cf5d03d3850fadaee06aa4a"
   },
   "source": [
    "## 2. Importing dataset\n",
    "\n",
    "We will use Python Pandas package to import the dataset and play with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "1ca1afc6bc2c35f4851129d1f60b1ae50c62b999"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../input/train.csv')\n",
    "test_data = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "26d363f55649abfe8506c1164428bf212d81dfab"
   },
   "source": [
    "## 3. Analysing the dataset\n",
    "\n",
    "We will use pandas for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "01a917fcc72803eec2f465c30d651ebcc8d79067"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "8c7078f4a1cc38f706842b0bbc0b814b0b5840f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "853613098c96fb1637228de2d7bd10afc33072e7"
   },
   "source": [
    "The data is not fit to feed into machine learning model. We have to clean it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "3c1c9d80c5f8bd20c4e1f57fce5acd6183ac8171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n",
    "print('-'*50)\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5f16fecb0ec9e4b549005eeaf45c3e4a59a27130"
   },
   "source": [
    "After seeing these head of the dataset. We can comment on categorical features, numerical features, data types of features, typos in features and null or empty features.\n",
    "\n",
    "#### Categorical features: \n",
    "A categorical variable (sometimes called a nominal variable) is one that has two or more categories, but there is no intrinsic ordering to the categories. This is further classified as nominal, ordinal, ratio, or interval based.\n",
    "-  Categorical: Survived, Sex and Embarked\n",
    "-  Ordinal: Pclass\n",
    "\n",
    "#### Numerical Features:\n",
    "As the name suggest, these values are numerical in nature and changes from sample to sample. This is further classified as discrete, continuous, or timeseries based.\n",
    "-  Continuous: Age, Fare\n",
    "-  Discrete: SibSp, Parch\n",
    "\n",
    "#### Data types of features:\n",
    "\n",
    "-  Seven features are integer or floats. Six in case of test dataset\n",
    "-  Five features are strings (object)\n",
    "-  MIXED DATA TYPES: Ticket is a mix of numeric and alphanumeric data types. Cabin is alphanumeric\n",
    "\n",
    "#### Featurs with error and typos:\n",
    "-  Name feature may contain errors or typos ass there are several ways to write a name\n",
    "\n",
    "#### Null or Empty Features:\n",
    "-  Age, Cabin and Embarked containes a lot of null values for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "4a43e35c969bb485a0df971732dc09d4a278868d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "82beb4337990235fda8d60c44cf781faa222f9e6"
   },
   "source": [
    "Points to be taken from these numerical features:\n",
    "\n",
    "-  Total samples are 891 i.e. 40% of the actual number of passengers on board the Titanic(2224)\n",
    "-  Survived is a categorical feature with 0 or 1 values.\n",
    "-  Most expensive ticket is $512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "bafac3d3af7912625fd3c0f7d4885da585f3a2d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Christmann, Mr. Emil</td>\n",
       "      <td>male</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name   Sex    Ticket        Cabin Embarked\n",
       "count                    891   891       891          204      889\n",
       "unique                   891     2       681          147        3\n",
       "top     Christmann, Mr. Emil  male  CA. 2343  C23 C25 C27        S\n",
       "freq                       1   577         7            4      644"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3a9afb279d12879d5693613f29d2da73acf4e65a"
   },
   "source": [
    "Points to be taken from these categorical features:\n",
    "\n",
    "-  No person with same name.\n",
    "-  Sex variable have two possible values with 65% male (top=male, freq= 577/count=891)\n",
    "-  Cabin values have several duplicates as many passengers shared cabin.\n",
    "-  S port is used most among the three possible values.\n",
    "-  Ticket feature has 681 unique values i.e.: 22% duplicate ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0376f83f53756b0f61c3f803bfbfe7fb7240f9df"
   },
   "source": [
    "## 4. Assumptions based on data analysis done so far:\n",
    "\n",
    "#### Based on our data analysis so far. We can state that:\n",
    "\n",
    "-  Ticket Feature contains 22% duplicates and can be dropped. As there may not be a correlation b/w Ticket and Survival\n",
    "-  Cabin feature can be dropped as it is highly incomplete and contains null values\n",
    "-  We can drop PassengerId as it does not contribute to survival\n",
    "-  We can create a new feature called Title for Name feature\n",
    "-  We can create a new feature called FamilySize based on Parch and SibSp to get total count of family members on board\n",
    "-  We should complete Age feature as it is directly correlated to survival\n",
    "-  Women might have been more likely to have survived\n",
    "-  Children below some certain age were also more likely to have survived\n",
    "-  The upper class passengers were more likely to have survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "537a5845391b7aa8b760fe212e1955bd21cdf133"
   },
   "source": [
    "## 5. Actions based on assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a3bd8e82c9c5c2f6fc66b7d4c9a111af35d82bdb"
   },
   "outputs": [],
   "source": [
    "#drop the Cabin and Ticket columns in both dataset. We also don't need the PassengerId in training dataset.\n",
    "\n",
    "train_data.drop(labels = ['PassengerId', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "test_data.drop(labels = ['Ticket', 'Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d3d70a6e54b1c0df2c1c40cee0aad9c600e38e53"
   },
   "source": [
    "Let's see the number of null values now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "120c8f8ab2ac21097a853848671341526f7ed8e6"
   },
   "outputs": [],
   "source": [
    "print('Training Data')\n",
    "print(pd.isnull(train_data).sum())\n",
    "print(\"-\"*50)\n",
    "print('Testing Data')\n",
    "print(pd.isnull(test_data).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a1b7c75ce15111623c75d65da96a139057ca844"
   },
   "source": [
    "#### Age columns seems to have null values.\n",
    "\n",
    "We will look at the distribution of Age column to see if it's skewed or symmetrical. This will help us to determine what values to replaec wit NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "489be66b2e86db6e356cbe65f5c83009053cba7f"
   },
   "outputs": [],
   "source": [
    "sns.distplot(train_data['Age'].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4df188cf4c4f4027f60cf9570fea2a33d990cd1d"
   },
   "source": [
    "As it is evident from the graph. The distribution is slightly skewed right. That's why we will fill the null values with median for better accuracy.\n",
    "\n",
    "I know you have questions here. Ask me in the comments section. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e1783dbee363a553cb31db92b617d4c56aea1262"
   },
   "outputs": [],
   "source": [
    "train_data['Age'].fillna(train_data['Age'].median(), inplace= True)\n",
    "test_data['Age'].fillna(test_data['Age'].median(), inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9eb6b1df93b49129b3d0f40a973356b6dfd091db"
   },
   "source": [
    "Since, We know from previous steps that \"S\" is the most Embarked port. Let's fill the null values in Embarked with \"S\" port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15e4828ed9961b8c3b5c80f9052ecd8c4b799364"
   },
   "outputs": [],
   "source": [
    "train_data['Embarked'].fillna(\"S\", inplace = True)\n",
    "test_data['Fare'].fillna(test_data['Fare'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e93b59361dd4f781e9d8e578f23e70c8673a31d5"
   },
   "source": [
    "Let's see the status of null values now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e1e49757288074ceda38e4573b3a696593f79e0"
   },
   "outputs": [],
   "source": [
    "print('Training Data')\n",
    "print(pd.isnull(train_data).sum())\n",
    "print(\"-\"*50)\n",
    "print('Testing Data')\n",
    "print(pd.isnull(test_data).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0199992558bfafbe32889f6c420a7a56fdb48bf2"
   },
   "source": [
    "Yes!! We got rid of missing values. Now let's see our cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59e397a72420ba30f39f9f435a30a8f0b4bb3940"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6c4ec4c5744bee8dfe285d48d89695a16fa6b879"
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb72e8a968a13f02b1c8ed6afdd22a606bae0c0e"
   },
   "source": [
    "## 6. Visualizing by Plotting Data\n",
    "\n",
    "Visualizing the data is important to see the trends and general associations of Variables. We can make different kinds of graphs for the features we want to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad3ee45596c8a687b31983f198c44420fcf73183"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.tight_layout()\n",
    "sns.barplot(x='Sex', y='Survived', data=train_data)\n",
    "plt.title('Distribution of Survival based on Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "14158a152c2cf9b6061f9b4360b0ce67e165c433"
   },
   "source": [
    "Clearly, Women were the top survivors.\n",
    "\n",
    "Also, Gender is a good feature to use for our machine learning model. But, we have to engineer it before feeding into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "25618e23a340aac0025ee6c92931a56de0068a28"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.tight_layout()\n",
    "sns.barplot(x='Pclass', y='Survived', data=train_data)\n",
    "plt.title('Distribution of Survival based on Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5ea7dd1b5fd982fc39761a7fc2b1c6c664dba138"
   },
   "source": [
    "So, The first class people were more likely to survive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "509da61be2335a3303fde4c8de80107cb06397af"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.tight_layout()\n",
    "sns.barplot(x='Pclass', y='Survived', hue='Sex', data=train_data)\n",
    "plt.title('Distribution of Survival based on Gender and Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4972a44b68a77b2329c4b487905ebb6e05edba82"
   },
   "source": [
    "So, Class also plays an important role in surival of the passengers. 1st Class were more likely to survive than other classes passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3371b8bc7d9ed44c5c8b00043eff0597c22d1614"
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train_data, col=\"Survived\", margin_titles=True)\n",
    "g.map(plt.hist, \"Age\", color=\"steelblue\", bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d7136aa350f70995a3a47b3b12a79fe7784591c2"
   },
   "outputs": [],
   "source": [
    "sns.swarmplot(x=\"Survived\", y=\"Age\", hue=\"Sex\", palette=[\"r\", \"c\", \"y\"], data=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c5eda5d3f30a033fb8e137de31a628d3dc6d6d8"
   },
   "source": [
    "As evident from the these distributions that younger people were more likely to survive than those of older people. Also, There were more females who survived.\n",
    "\n",
    "Let's drap a pairplot to see possible relatins between all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eb2d1d7c6ccc1827d533731659743ae3a2251069"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cdf994b8b464464adba538d9bdbedbf45595bd4a"
   },
   "source": [
    "## 7. Feature Engineering\n",
    "\n",
    "Categorical features needs to be represented as numerical values before we feed it into the machine learning model. \"Sex\" and \"Embarked\" columns needs to be engineered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e802f1474219a30de78b7140b6259ecd01ec4bf"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cf2c5f0878e92bef29947b5c6c6740afc4df9bb7"
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9007a3674fae1a888cb37ba68960e22fa2ea5ef3"
   },
   "source": [
    "We can change Sex to binary, as either 1 for female or 0 for male. We do the same for Embarked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6256c6266b4c3b1aecec01e4a0eeee74928832ec"
   },
   "outputs": [],
   "source": [
    "train_data['Sex'] = train_data['Sex'].map( {'female': 1, 'male': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c3a739d7f25294cd0e7dbf7c5fe1cde92254a69"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d46eb6a24d05664bbcb3ce31c7092ac16838e83"
   },
   "outputs": [],
   "source": [
    "test_data['Sex'] = test_data['Sex'].map( {'female': 1, 'male': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "edb9646135d047d2f37e362cf2ff596126e92007"
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c987055343020fd8cba215ca674d0e08e1da162d"
   },
   "source": [
    "Let's do the same with Embarked column. Since, We already took care of the NaN values then we just have to convert the categorical port feature to numerical port feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a938c9c5dab92dceda041bbc0e8db33eb9ad2a70"
   },
   "outputs": [],
   "source": [
    "train_data['Embarked'] = train_data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
    "test_data['Embarked'] = test_data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b8824fc6b08a887c12519fb33addb82582f29a1f"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "848ca7d5edb2b86f8ce765629c0bae2ffb487b82"
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "277d07e34e14ba5389562e0d5987644a5434eedc"
   },
   "source": [
    "## 8. Create New Features\n",
    "\n",
    "Sometimes in a dataset individual features might be of no use. But, if you create a new features using them, then you might be able to get some more insights into the problem. But, who knows. So, Let's try it out.\n",
    "\n",
    "After reading on kaggle discussions, I came to know that we can combine \"SibSp\" and \"Parch\" and make a new feature named \"FamilySize\". Since, People who have had family might have risked their life to search for their family.\n",
    "\n",
    "Also, We can make a new feature for people who were alone on the ship. We can name it as \"Single\" or \"IsAlone\" or whatever you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7625844ee4c2609e6f88049443d26d5d7f9a5de7"
   },
   "outputs": [],
   "source": [
    "train_data[\"FamilySize\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1\n",
    "test_data[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f192b3ea74b7b91365e49ca34145b293b3ea73fb"
   },
   "outputs": [],
   "source": [
    "train_data['Single'] = train_data.FamilySize.apply(lambda x: 1 if x == 1 else 0)\n",
    "test_data['Single'] = test_data.FamilySize.apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2d02e9ab37cb48a0dbbfab67e25d261780a46a93"
   },
   "source": [
    "Let's have a look at our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82c6af7863cd2d9adf8171b8378185eaf32c3303"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c7d26b2fa471740febd872999075b9d08df16bd"
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bae21e59daa253036e7bd64364d0a6be607031c7"
   },
   "source": [
    "Everything looks out numeric except the name column. Let's engineer the name column also.\n",
    "\n",
    "Since,name column is not used. We can extract the title from the names and then encode them in to numeric values. Then we can use name column to predict the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3160fe5d95e54aeaaffc27870d1e790da0f807c1"
   },
   "outputs": [],
   "source": [
    "train_data['Title'] = train_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False) ##Regular Expression <3\n",
    "test_data['Title'] = test_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "pd.crosstab(train_data['Title'], train_data['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "44f83991ef1fcceb248cc2d730914db58967b61a"
   },
   "source": [
    "Let's replace title with common name and the unique ones as unique.\n",
    "\n",
    "Let's also combine the dataset into an array so that we can perform operations on both dataset using a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fdc81c5ac40fc54ef6e4bc58ec8f1949f660a753"
   },
   "outputs": [],
   "source": [
    "title_list = list(set(train_data['Title']))\n",
    "title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "87ac34c7b6d72ee88d8b775896135ddb8f8434a8"
   },
   "outputs": [],
   "source": [
    "mix = [train_data, test_data] ## Just so save ourself some time and repeated code.\n",
    "\n",
    "for dt in mix:\n",
    "    dt['Title'] = dt['Title'].replace(['Dr', 'Col', 'Sir', 'Countess', 'Jonkheer', 'Lady', 'Don', 'Capt', 'Major', 'Rev', \\\n",
    "                                      ], 'Unique')\n",
    "    dt['Title'] = dt['Title'].replace('Mlle', 'Miss')\n",
    "    dt['Title'] = dt['Title'].replace('Ms', 'Miss')\n",
    "    dt['Title'] = dt['Title'].replace('Mme', 'Mrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "de9f6fda6f48a9d54803f265ae301b2d81434099"
   },
   "outputs": [],
   "source": [
    "map_title = {'Mrs': 1, 'Miss': 2, 'Mr': 3, 'Master': 4, 'Unique': 5}\n",
    "\n",
    "for dt in mix:\n",
    "    dt['Title'] = dt['Title'].map(map_title)\n",
    "    dt['Title'] = dt['Title'].fillna(0)\n",
    "    \n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "465a840dc62efb5e42fd64684ba71d822a7b91b4"
   },
   "source": [
    "Nice!\n",
    "\n",
    "We can now drop \"Name\", \"SibSp\" and \"Parch\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6549e3edb0b0986e58fbea7e43f0e3a87fd3f9cf"
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['Name', 'SibSp', 'Parch'], axis=1)\n",
    "test_data = test_data.drop(['Name', 'SibSp', 'Parch'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d500d39fec66d061c6872daba31e30970ffa5bd"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "de858307a8477f5790843ec7d32b99b850c41695"
   },
   "source": [
    "## 9. Build Model and Make Prediction\n",
    "\n",
    "We are all set to build our model. I will be using different models and will select the one with the best accuracy.\n",
    "\n",
    "\n",
    "\n",
    "#### Import all the sklearn models to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4843d73d1988b1135ffdb482931fa549d892af19"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9088b8e400e32e8a056922cd14a354b57766d894"
   },
   "outputs": [],
   "source": [
    "# to evaluate model performance, we can use the accuracy_score function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "80359a7a1f2b93dabfa16e711fc539b37200d69c"
   },
   "source": [
    "Let's define features in Training/Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a92633b0bdc5a428719c98d6959fd073eec4b160"
   },
   "outputs": [],
   "source": [
    "X_train = train_data.drop(labels=['Survived'], axis=1)\n",
    "y_train = train_data['Survived']\n",
    "X_test = test_data.drop('PassengerId',axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "674def5577216e48b75ef9bfee93da357d6fa40c"
   },
   "outputs": [],
   "source": [
    "X_train.shape,  y_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "495179902b443b188d38e622f7a314ab4fc7d916"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "accuracy_log = logreg.score(X_train, y_train)\n",
    "print(\"The accuracy for the Logistic Regression is: \" + str(accuracy_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b36c5b9212058b61f08e2e17a4a6e89da043a99f"
   },
   "outputs": [],
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "accuracy_svc = svc.score(X_train, y_train)\n",
    "print(\"The accuracy for Support Vector Machines is:\" + str(accuracy_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f0d3ca17915916dc094ac52a95c9799bb79a3f03"
   },
   "outputs": [],
   "source": [
    "# K Nearest Neighbours\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "accuracy_knn = knn.score(X_train, y_train)\n",
    "print(\"The accuracy of KNN is: \" + str(accuracy_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8fda9f25ec56f541b67cc4dbc246a083a5a5e95b"
   },
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, y_train)\n",
    "Y_pred = gaussian.predict(X_test)\n",
    "accuracy_gnb = gaussian.score(X_train, y_train)\n",
    "print(\"The accuracy of Gaussian Naive Bayes is: \" + str(accuracy_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1f8fbe9fc136321cdcf6a98b7541cb63e891ac53"
   },
   "outputs": [],
   "source": [
    "# Linear SVC\n",
    "\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train, y_train)\n",
    "Y_pred = linear_svc.predict(X_test)\n",
    "accuracy_lsvc = linear_svc.score(X_train, y_train)\n",
    "print(\"The accuracy of linear SVC is: \" + str(accuracy_lsvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5688f94fe4e9ee93ef3c5279209d6f59fe821248"
   },
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "\n",
    "d_tree = DecisionTreeClassifier()\n",
    "d_tree.fit(X_train, y_train)\n",
    "Y_pred = d_tree.predict(X_test)\n",
    "accuracy_d_tree = d_tree.score(X_train, y_train)\n",
    "print(\"The accuracy of Decision Tree is: \" + str(accuracy_d_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "25a2baea543cf6f341ce54f83c6c0f2d2e41e27a"
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100) #tried with 80, 90, 100 no difference\n",
    "random_forest.fit(X_train, y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "accuracy_r_forest = random_forest.score(X_train, y_train)\n",
    "print(\"The accuracy of Random Forest is: \" + str(accuracy_r_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6e5d55e3841c1dc12f1e2a0b61247354e2609104"
   },
   "source": [
    "## 10. Compare Model Performances\n",
    "\n",
    "We have done predictions with many models. Now, we should see which model performed the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aeb630d4b4027267067c2ba8a6a3f91def075a28"
   },
   "outputs": [],
   "source": [
    "model_performance = pd.DataFrame({\n",
    "    \"Model\": [\"Logistic Regression\", \"Support Vector Machines\", \"K Nearest Neighbours\", \"Gaussian Naive Bayes\",\n",
    "             \"Linear SVC\", \"Decision Tree\", \"Random Forest\"],\n",
    "    \"Accuracy\": [accuracy_log, accuracy_svc, accuracy_knn, accuracy_gnb, accuracy_lsvc, accuracy_d_tree, accuracy_r_forest]\n",
    "})\n",
    "\n",
    "model_performance.sort_values(by=\"Accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "76d9a6468de8afad4eb71c5a784eacbd84444c94"
   },
   "source": [
    "It's is clear that both Decision Tree and Random Forest score the same. We choose to use the Random Forest as they tend not to overfit as decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "339df38f93b23111f331c47257c75d31c5246532"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_data[\"PassengerId\"],\n",
    "    \"Survived\": Y_pred\n",
    "})\n",
    "\n",
    "#submission.to_csv(\"../output/titanic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b5ee4aa23090754e96c5271771d92135cfc0b2cd"
   },
   "source": [
    "### References: \n",
    "* [startupsci](https://www.kaggle.com/startupsci/titanic-data-science-solutions)\n",
    "* [Blog](https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
